{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de30d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 Module import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Validation Dataset Preparation\n",
    "\n",
    "##1.1 Dataset input \n",
    "file_path = 'CRISPRoffT_filtered.csv'\n",
    "df = pd.read_csv(file_path, sep=',')\n",
    "\n",
    "##1.2 Dataset filtering \n",
    "filtered_df = df[(df['Species'] == \"Homo sapiens\") & \\\n",
    "                 (df['Cas9_type'] == \"SpCas9\") & \\\n",
    "                 (df['gRNA'].isin([\"sgRNA\",\"Alt-R XT 2-part gRNA\"]))\n",
    "                ]\n",
    "\n",
    "##1.3 Dataset subsetting\n",
    "\n",
    "validated_df = filtered_df[(filtered_df['Validation'].notna()) & (filtered_df['Identity'] == \"OFF\")]\n",
    "validated_df = validated_df[~validated_df['Target_sequence'].str.contains('I', case=False, na=False)]\n",
    "\n",
    "validated_onlyMis_df = validated_df[(validated_df['Bulge'].isna()) & (validated_df['Bulge2'].isna())]\n",
    "non_validated_df = filtered_df[filtered_df['Validation'].isna()]\n",
    "\n",
    "#### 1.3.1 Drop duplicates as some pairs were identical but retrieved in different conditions \n",
    "validated_onlyMis_df.to_csv('validated_onlyMis_df.csv', index=False)\n",
    "\n",
    "validated_onlyMis_df = validated_onlyMis_df.drop_duplicates(\n",
    "    subset=['Guide_sequence', 'Target_sequence', 'Validation'], \n",
    "    keep='first'\n",
    ")\n",
    "validated_onlyMis_df.to_csv('validated_onlyMis_df_removed_duplicates.csv', index=False)\n",
    "\n",
    "validated_df_sgRNA_DNA = validated_df[['Guide_sequence', 'Target_sequence','Validation']]\n",
    "validated_df_sgRNA_DNA = validated_df_sgRNA_DNA.drop_duplicates()\n",
    "validated_df_sgRNA_DNA_tp = validated_df_sgRNA_DNA[validated_df_sgRNA_DNA['Validation'] == True ]\n",
    "validated_df_sgRNA_DNA['Validation'] = validated_df_sgRNA_DNA['Validation'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "\n",
    "validated_onlyMis_df_sgRNA_DNA = validated_onlyMis_df[['Guide_sequence', 'Target_sequence','Validation']]\n",
    "validated_onlyMis_df_sgRNA_DNA = validated_onlyMis_df_sgRNA_DNA.drop_duplicates()\n",
    "validated_onlyMis_df_sgRNA_DNA_tp = validated_onlyMis_df_sgRNA_DNA[validated_onlyMis_df_sgRNA_DNA['Validation'] == True ]\n",
    "validated_onlyMis_df_sgRNA_DNA['Validation'] = validated_onlyMis_df_sgRNA_DNA['Validation'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "validated_onlyMis_df_sgRNA_DNA_tp.to_csv('validated_onlyMis_df_sgRNA_DNA_tp.csv', index=False)\n",
    "validated_df_sgRNA_DNA_tp.to_csv('validated_df_sgRNA_DNA_tp.csv', index=False)\n",
    "validated_onlyMis_df_sgRNA_DNA.to_csv('validated_onlyMis_df_sgRNA_DNA.csv', index=False)\n",
    "\n",
    "\n",
    "print(len(validated_df),len(validated_onlyMis_df),len(non_validated_df))\n",
    "\n",
    "print(len(validated_df_sgRNA_DNA), len(validated_onlyMis_df_sgRNA_DNA), len(validated_df_sgRNA_DNA_tp), len(validated_onlyMis_df_sgRNA_DNA_tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd10fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Public Dataset Preparation\n",
    "\n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/HEK293T.pkl', \"rb\") as f:\n",
    "    data_HEK293T = pickle.load(f)\n",
    "    \n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/K562.pkl', \"rb\") as f:\n",
    "    data_K562 = pickle.load(f)  \n",
    "    \n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/II3.pkl', \"rb\") as f:\n",
    "    data_II3 = pickle.load(f)\n",
    "    \n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/II4.pkl', \"rb\") as f:\n",
    "    data_II4 = pickle.load(f)  \n",
    "    \n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/II5.pkl', \"rb\") as f:\n",
    "    data_II5 = pickle.load(f)\n",
    "    \n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/II6.pkl', \"rb\") as f:\n",
    "    data_II6 = pickle.load(f)    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Integrate validation dataset\n",
    "\n",
    "##3.1 Exclude idential pairs in validated dataset\n",
    "sgRNAs_val = set(validated_onlyMis_df_sgRNA_DNA['Guide_sequence'])\n",
    "selected_sgRNAs_list = []\n",
    "for i in range(5):\n",
    "    random.seed(42+i)\n",
    "    selected_sgRNAs = random.sample(list(sgRNAs_val), 5)\n",
    "    selected_sgRNAs_list.append(selected_sgRNAs)\n",
    "    \n",
    "data_HEK293Ts = []\n",
    "data_K562s = []\n",
    "data_II3s = []\n",
    "data_II4s = []\n",
    "data_II5s = []\n",
    "data_II6s = []\n",
    "\n",
    "data_testing = []\n",
    "\n",
    "##3.2 Combine validation dataset with public datasets\n",
    "q = 0\n",
    "for sgRNAs_val in selected_sgRNAs_list:\n",
    "    \n",
    "    ## Validated_only dataset\n",
    "\n",
    "    \"\"\" Generate the validated_only datasets for training a\n",
    "    nd testing, the validated_only dataset contains same sgRNA as \n",
    "    public datasets\n",
    "    \"\"\"  \n",
    "\n",
    "    data_val = validated_onlyMis_df_sgRNA_DNA[~validated_onlyMis_df_sgRNA_DNA['Guide_sequence'].isin(sgRNAs_val)]\n",
    "    data_val.rename(columns={'Guide_sequence': 'sgRNA',\n",
    "                               'Target_sequence': 'DNA',\n",
    "                               'Validation': 'label'}, inplace=True)\n",
    "    \n",
    "    ## To save the validation datasets for training \n",
    "    data_val.to_csv('./Datasets/Val_only' + str(q) + '.csv', index = False) \n",
    "    \n",
    "    data_test = validated_onlyMis_df_sgRNA_DNA[validated_onlyMis_df_sgRNA_DNA['Guide_sequence'].isin(sgRNAs_val)]\n",
    "    data_test.rename(columns={'Guide_sequence': 'sgRNA',\n",
    "                               'Target_sequence': 'DNA',\n",
    "                               'Validation': 'label'}, inplace=True)\n",
    "    \n",
    "    ## To save the testing datasets\n",
    "    data_test.to_csv('./Datasets/Testing' + str(q) + '.csv', index = False)\n",
    "    q += 1\n",
    "    data_testing.append(data_test)\n",
    "    \n",
    "    print(len(data_val),len(data_test))\n",
    "    \n",
    "\n",
    "    ## filter sgRNAs from original dataset\n",
    "    \n",
    "    data_HEK293T_filtered = data_HEK293T[~data_HEK293T['sgRNA'].isin(sgRNAs_val)]\n",
    "    data_K562_filtered = data_K562[~data_K562['sgRNA'].isin(sgRNAs_val)]\n",
    "    data_II3_filtered = data_II3[~data_II3['sgRNA'].isin(sgRNAs_val)]\n",
    "    data_II4_filtered = data_II4[~data_II4['sgRNA'].isin(sgRNAs_val)]\n",
    "    data_II5_filtered = data_II5[~data_II5['sgRNA'].isin(sgRNAs_val)]\n",
    "    data_II6_filtered = data_II6[~data_II6['sgRNA'].isin(sgRNAs_val)]\n",
    "\n",
    "    \n",
    "    data_HEK293Ts.append(data_HEK293T_filtered)\n",
    "    data_K562s.append(data_K562_filtered)\n",
    "    data_II3s.append(data_II3_filtered)\n",
    "    data_II4s.append(data_II4_filtered)\n",
    "    data_II5s.append(data_II5_filtered)\n",
    "    data_II6s.append(data_II6_filtered)\n",
    "\n",
    "    \n",
    "    data_K562_combined = pd.concat([data_K562_filtered, data_val], ignore_index=True)\n",
    "    data_HEK293T_combined = pd.concat([data_HEK293T_filtered, data_val], ignore_index=True)\n",
    "    data_II3_combined = pd.concat([data_II3_filtered, data_val], ignore_index=True)\n",
    "    data_II4_combined = pd.concat([data_II4_filtered, data_val], ignore_index=True)\n",
    "    data_II5_combined = pd.concat([data_II5_filtered, data_val], ignore_index=True)\n",
    "    data_II6_combined = pd.concat([data_II6_filtered, data_val], ignore_index=True)\n",
    "\n",
    "    data_HEK293Ts.append(data_HEK293T_combined)\n",
    "    data_K562s.append(data_K562_combined)\n",
    "    data_II3s.append(data_II3_combined)\n",
    "    data_II4s.append(data_II4_combined)\n",
    "    data_II5s.append(data_II5_combined)\n",
    "    data_II6s.append(data_II6_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951eabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Resampling using SMOTEENN\n",
    "\n",
    "##4.1 Class and function for DNA sequence conversion \n",
    "class SeqTranslate:\n",
    "    def __init__(self):\n",
    "        # Define the mapping for encoding and decoding\n",
    "        self.nucleotide_to_number = {'A': 1, 'C': 2, 'G': 3, 'T': 4}\n",
    "        self.number_to_nucleotide = {v: k for k, v in self.nucleotide_to_number.items()}\n",
    "\n",
    "    def encode(self, sequence):\n",
    "        \"\"\"\n",
    "        Encode a nucleotide sequence into numeric representation.\n",
    "\n",
    "        Args:\n",
    "            sequence (str): The nucleotide sequence (e.g., \"ACGT\").\n",
    "\n",
    "        Returns:\n",
    "            list: A list of integers representing the sequence.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return [self.nucleotide_to_number[nuc] for nuc in sequence]\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Invalid nucleotide found in sequence. Allowed: A, C, G, T\")\n",
    "\n",
    "    def decode(self, numeric_sequence):\n",
    "        \"\"\"\n",
    "        Decode a numeric sequence back into nucleotide representation.\n",
    "\n",
    "        Args:\n",
    "            numeric_sequence (list): A list of integers (e.g., [1, 2, 3, 4]).\n",
    "\n",
    "        Returns:\n",
    "            str: The decoded nucleotide sequence.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return ''.join(self.number_to_nucleotide[num] for num in numeric_sequence)\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Invalid number found in sequence. Allowed: 1, 2, 3, 4\")\n",
    "\n",
    "# Example usage\n",
    "translator = SeqTranslate()\n",
    "\n",
    "# Encoding\n",
    "sequence = \"ACGTACG\"\n",
    "encoded = translator.encode(sequence)\n",
    "print(\"Encoded sequence:\", encoded)\n",
    "\n",
    "# Decoding\n",
    "decoded = translator.decode(encoded)\n",
    "print(\"Decoded sequence:\", decoded)\n",
    "\n",
    "\n",
    "def SMOTEENN_resampling(df, random_num):\n",
    "    \n",
    "    Encoded_seqs = []\n",
    "    Labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        on_target = row['sgRNA']\n",
    "        off_target = row['DNA']\n",
    "        label = row['label']\n",
    "\n",
    "        translator = SeqTranslate()\n",
    "        encoded_seq = translator.encode(on_target + off_target)\n",
    "\n",
    "        Encoded_seqs.append(encoded_seq)\n",
    "        Labels.append(int(label))\n",
    "\n",
    "    X = pd.DataFrame(Encoded_seqs)\n",
    "    y = pd.DataFrame(Labels)\n",
    "    \n",
    "    print(len(X),len(y))\n",
    "\n",
    "    ###1.5.2 resampling with SMOTEENN\n",
    "\n",
    "    smote_enn = SMOTEENN(random_state=random_num)\n",
    "\n",
    "    # Resample the data\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "    resampled_ont = []\n",
    "    resampled_offt = []\n",
    "    \n",
    "    print(len(X_resampled),len(y_resampled))\n",
    "\n",
    "    for index, row in X_resampled.iterrows():\n",
    "\n",
    "        translator = SeqTranslate()\n",
    "        decoded_seq = translator.decode(row)\n",
    "\n",
    "        on_target = decoded_seq[:23]\n",
    "        off_target = decoded_seq[23:]\n",
    "\n",
    "        resampled_ont.append(on_target)\n",
    "        resampled_offt.append(off_target)\n",
    "    \n",
    "    return resampled_ont,resampled_offt,y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9265471",
   "metadata": {},
   "outputs": [],
   "source": [
    "##4.2 Dataset resampling using SMOTEENN\n",
    "\n",
    "\n",
    "training_sets_HEK293T = []\n",
    "training_sets_K562 = []\n",
    "training_sets_II3 = []\n",
    "training_sets_II4 = []\n",
    "training_sets_II5 = []\n",
    "training_sets_II6 = []\n",
    "label_sets_train_HEK293T = []\n",
    "label_sets_train_K562 = []\n",
    "label_sets_train_II3 = []\n",
    "label_sets_train_II4 = []\n",
    "label_sets_train_II5 = []\n",
    "label_sets_train_II6 = []\n",
    "\n",
    "# resampling and save the training datasets\n",
    "for i in range(10):\n",
    "    \n",
    "    data_HEK293T_filtered = data_HEK293Ts[i]\n",
    "    data_K562_filtered = data_K562s[i]\n",
    "    data_II3_filtered = data_II3s[i]\n",
    "    data_II4_filtered = data_II4s[i]\n",
    "    data_II5_filtered = data_II5s[i]\n",
    "    data_II6_filtered = data_II6s[i]\n",
    "\n",
    "    random_num = 42\n",
    "\n",
    "    resampled_ont_HEK293T, resampled_offt_HEK293T, y_resampled_HEK293T = SMOTEENN_resampling(data_HEK293T_filtered, random_num)\n",
    "    np.savez('training_sets_HEK293T_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_HEK293T)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_HEK293T)[0].to_numpy(),\n",
    "             label=y_resampled_HEK293T[0].to_numpy())\n",
    "    resampled_ont_K562, resampled_offt_K562, y_resampled_K562 = SMOTEENN_resampling(data_K562_filtered, random_num)\n",
    "    np.savez('training_sets_K562_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_K562)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_K562)[0].to_numpy(),\n",
    "            label=y_resampled_K562[0].to_numpy())\n",
    "    resampled_ont_II3, resampled_offt_II3, y_resampled_II3 = SMOTEENN_resampling(data_II3_filtered, random_num)\n",
    "    np.savez('training_sets_II3_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_II3)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_II3)[0].to_numpy(),\n",
    "            label=y_resampled_II3[0].to_numpy())\n",
    "    resampled_ont_II4, resampled_offt_II4, y_resampled_II4 = SMOTEENN_resampling(data_II4_filtered, random_num)\n",
    "    np.savez('training_sets_II4_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_II4)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_II4)[0].to_numpy(),\n",
    "            label=y_resampled_II4[0].to_numpy())\n",
    "    resampled_ont_II5, resampled_offt_II5, y_resampled_II5 = SMOTEENN_resampling(data_II5_filtered, random_num)\n",
    "    np.savez('training_sets_II5_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_II5)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_II5)[0].to_numpy(),\n",
    "            label=y_resampled_II5[0].to_numpy())\n",
    "    resampled_ont_II6, resampled_offt_II6, y_resampled_II6 = SMOTEENN_resampling(data_II6_filtered, random_num)\n",
    "    np.savez('training_sets_II6_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_II6)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_II6)[0].to_numpy(),\n",
    "            label=y_resampled_II6[0].to_numpy())\n",
    "\n",
    "    training_sets_HEK293T.append([pd.DataFrame(resampled_ont_HEK293T)[0].to_numpy(),pd.DataFrame(resampled_offt_HEK293T)[0].to_numpy()])\n",
    "    training_sets_K562.append([pd.DataFrame(resampled_ont_K562)[0].to_numpy(),pd.DataFrame(resampled_offt_K562)[0].to_numpy()])\n",
    "    training_sets_II3.append([pd.DataFrame(resampled_ont_II3)[0].to_numpy(),pd.DataFrame(resampled_offt_II3)[0].to_numpy()])\n",
    "    training_sets_II4.append([pd.DataFrame(resampled_ont_II4)[0].to_numpy(),pd.DataFrame(resampled_offt_II4)[0].to_numpy()])\n",
    "    training_sets_II5.append([pd.DataFrame(resampled_ont_II5)[0].to_numpy(),pd.DataFrame(resampled_offt_II5)[0].to_numpy()])\n",
    "    training_sets_II6.append([pd.DataFrame(resampled_ont_II6)[0].to_numpy(),pd.DataFrame(resampled_offt_II6)[0].to_numpy()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (OT_review)",
   "language": "python",
   "name": "ot_review"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
