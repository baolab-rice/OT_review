{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8c096b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 Module import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7538786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_984800/90339620.py:5: DtypeWarning: Columns (10,12,14,15,16,17,18,19,20,27,29,30,31,32,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=',')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5040 2764 228277\n",
      "2869 2764 447 417\n"
     ]
    }
   ],
   "source": [
    "#1 Validation Dataset Preparation\n",
    "\n",
    "##1.1 Dataset input \n",
    "file_path = 'CRISPRoffT_filtered.csv'\n",
    "df = pd.read_csv(file_path, sep=',')\n",
    "\n",
    "##1.2 Dataset filtering \n",
    "filtered_df = df[(df['Species'] == \"Homo sapiens\") & \\\n",
    "                 (df['Cas9_type'] == \"SpCas9\") & \\\n",
    "                 (df['gRNA'].isin([\"sgRNA\",\"Alt-R XT 2-part gRNA\"]))\n",
    "                ]\n",
    "\n",
    "##1.3 Dataset subsetting\n",
    "\n",
    "validated_df = filtered_df[(filtered_df['Validation'].notna()) & (filtered_df['Identity'] == \"OFF\")]\n",
    "validated_df = validated_df[~validated_df['Target_sequence'].str.contains('I', case=False, na=False)]\n",
    "\n",
    "validated_onlyMis_df = validated_df[(validated_df['Bulge'].isna()) & (validated_df['Bulge2'].isna())]\n",
    "non_validated_df = filtered_df[filtered_df['Validation'].isna()]\n",
    "\n",
    "#### 1.3.1 Drop duplicates as some pairs were identical but retrieved in different conditions \n",
    "validated_onlyMis_df.to_csv('validated_onlyMis_df.csv', index=False)\n",
    "\n",
    "validated_onlyMis_df = validated_onlyMis_df.drop_duplicates(\n",
    "    subset=['Guide_sequence', 'Target_sequence', 'Validation'], \n",
    "    keep='first'\n",
    ")\n",
    "validated_onlyMis_df.to_csv('validated_onlyMis_df_removed_duplicates.csv', index=False)\n",
    "\n",
    "validated_df_sgRNA_DNA = validated_df[['Guide_sequence', 'Target_sequence','Validation']]\n",
    "validated_df_sgRNA_DNA = validated_df_sgRNA_DNA.drop_duplicates()\n",
    "validated_df_sgRNA_DNA_tp = validated_df_sgRNA_DNA[validated_df_sgRNA_DNA['Validation'] == True ]\n",
    "validated_df_sgRNA_DNA['Validation'] = validated_df_sgRNA_DNA['Validation'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "\n",
    "validated_onlyMis_df_sgRNA_DNA = validated_onlyMis_df[['Guide_sequence', 'Target_sequence','Validation']]\n",
    "validated_onlyMis_df_sgRNA_DNA = validated_onlyMis_df_sgRNA_DNA.drop_duplicates()\n",
    "validated_onlyMis_df_sgRNA_DNA_tp = validated_onlyMis_df_sgRNA_DNA[validated_onlyMis_df_sgRNA_DNA['Validation'] == True ]\n",
    "validated_onlyMis_df_sgRNA_DNA['Validation'] = validated_onlyMis_df_sgRNA_DNA['Validation'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "validated_onlyMis_df_sgRNA_DNA_tp.to_csv('validated_onlyMis_df_sgRNA_DNA_tp.csv', index=False)\n",
    "validated_df_sgRNA_DNA_tp.to_csv('validated_df_sgRNA_DNA_tp.csv', index=False)\n",
    "validated_onlyMis_df_sgRNA_DNA.to_csv('validated_onlyMis_df_sgRNA_DNA.csv', index=False)\n",
    "\n",
    "\n",
    "print(len(validated_df),len(validated_onlyMis_df),len(non_validated_df))\n",
    "\n",
    "print(len(validated_df_sgRNA_DNA), len(validated_onlyMis_df_sgRNA_DNA), len(validated_df_sgRNA_DNA_tp), len(validated_onlyMis_df_sgRNA_DNA_tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27b7f357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(validated_df_sgRNA_DNA['Guide_sequence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b4a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Public Dataset Preparation\n",
    "\n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/HEK293T.pkl', \"rb\") as f:\n",
    "    data_HEK293T = pickle.load(f)\n",
    "    \n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/K562.pkl', \"rb\") as f:\n",
    "    data_K562 = pickle.load(f)  \n",
    "    \n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/II3.pkl', \"rb\") as f:\n",
    "    data_II3 = pickle.load(f)\n",
    "    \n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/II4.pkl', \"rb\") as f:\n",
    "    data_II4 = pickle.load(f)  \n",
    "    \n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/II5.pkl', \"rb\") as f:\n",
    "    data_II5 = pickle.load(f)\n",
    "    \n",
    "with open('./SM_OT_Review/dataset_benchmarking2023/II6.pkl', \"rb\") as f:\n",
    "    data_II6 = pickle.load(f)    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59ffa56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sgRNA</th>\n",
       "      <th>DNA</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GCCTCTTTCCCACCCACCTTGGG</td>\n",
       "      <td>GTCTCTTTCCCAGCGACCTGGGG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GACTTGTTTTCATTGTTCTCAGG</td>\n",
       "      <td>GAGTCATTTTCATTGTCTTCATG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GGTGAGTGAGTGTGTGCGTGTGG</td>\n",
       "      <td>TGTGAGTGTGTGTGTGTGTGTGT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GGTGAGTGAGTGTGTGCGTGTGG</td>\n",
       "      <td>TGTGTGTTCGTGTGTGCGTGTGT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCCTCCCCAAAGCCTGGCCAGGG</td>\n",
       "      <td>GCTTCTCCAAAGCCTTCAGAGGG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132909</th>\n",
       "      <td>GGTGAGTGAGTGTGTGCGTGTGG</td>\n",
       "      <td>TGTGTGTGTGTGTGTATGTGTGC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132910</th>\n",
       "      <td>GGTGAGTGAGTGTGTGCGTGTGG</td>\n",
       "      <td>TGTGAGTGTGTGTGTGTGTGTGT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132911</th>\n",
       "      <td>GCCTCCCCAAAGCCTGGCCAGGG</td>\n",
       "      <td>TCAGCCCCAAAGCCTGGCCTGTT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132912</th>\n",
       "      <td>GGTGAGTGAGTGTGTGCGTGTGG</td>\n",
       "      <td>AGCGTGTGCGTGTGTGTGTGTGT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132913</th>\n",
       "      <td>GGTGAGTGAGTGTGTGCGTGTGG</td>\n",
       "      <td>GGTGAGTGTGTATGTGTGTGTGT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132914 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sgRNA                      DNA  label\n",
       "0       GCCTCTTTCCCACCCACCTTGGG  GTCTCTTTCCCAGCGACCTGGGG      0\n",
       "1       GACTTGTTTTCATTGTTCTCAGG  GAGTCATTTTCATTGTCTTCATG      0\n",
       "2       GGTGAGTGAGTGTGTGCGTGTGG  TGTGAGTGTGTGTGTGTGTGTGT      0\n",
       "3       GGTGAGTGAGTGTGTGCGTGTGG  TGTGTGTTCGTGTGTGCGTGTGT      0\n",
       "4       GCCTCCCCAAAGCCTGGCCAGGG  GCTTCTCCAAAGCCTTCAGAGGG      0\n",
       "...                         ...                      ...    ...\n",
       "132909  GGTGAGTGAGTGTGTGCGTGTGG  TGTGTGTGTGTGTGTATGTGTGC      0\n",
       "132910  GGTGAGTGAGTGTGTGCGTGTGG  TGTGAGTGTGTGTGTGTGTGTGT      0\n",
       "132911  GCCTCCCCAAAGCCTGGCCAGGG  TCAGCCCCAAAGCCTGGCCTGTT      0\n",
       "132912  GGTGAGTGAGTGTGTGCGTGTGG  AGCGTGTGCGTGTGTGTGTGTGT      0\n",
       "132913  GGTGAGTGAGTGTGTGCGTGTGG  GGTGAGTGTGTATGTGTGTGTGT      0\n",
       "\n",
       "[132914 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_HEK293T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac3db02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sgRNAs_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_HEK293T_filtered \u001b[38;5;241m=\u001b[39m data_HEK293T[\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;241m~\u001b[39m\u001b[43mdata_HEK293T\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msgRNA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDNA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msgRNAs_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m ]\n\u001b[1;32m      5\u001b[0m data_K562_filtered \u001b[38;5;241m=\u001b[39m data_K562[\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m~\u001b[39mdata_K562\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgRNA\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDNA\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01min\u001b[39;00m sgRNAs_val, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      9\u001b[0m data_II3_filtered \u001b[38;5;241m=\u001b[39m data_II3[\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m~\u001b[39mdata_II3\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgRNA\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDNA\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01min\u001b[39;00m sgRNAs_val, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/OT_review/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/OT_review/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/OT_review/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/envs/OT_review/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m data_HEK293T_filtered \u001b[38;5;241m=\u001b[39m data_HEK293T[\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;241m~\u001b[39mdata_HEK293T\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgRNA\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDNA\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01min\u001b[39;00m \u001b[43msgRNAs_val\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m ]\n\u001b[1;32m      5\u001b[0m data_K562_filtered \u001b[38;5;241m=\u001b[39m data_K562[\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m~\u001b[39mdata_K562\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgRNA\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDNA\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01min\u001b[39;00m sgRNAs_val, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      9\u001b[0m data_II3_filtered \u001b[38;5;241m=\u001b[39m data_II3[\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m~\u001b[39mdata_II3\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgRNA\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDNA\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01min\u001b[39;00m sgRNAs_val, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sgRNAs_val' is not defined"
     ]
    }
   ],
   "source": [
    "data_HEK293T_filtered = data_HEK293T[\n",
    "    ~data_HEK293T.apply(lambda row: (row['sgRNA'], row['DNA']) in sgRNAs_val, axis=1)\n",
    "]\n",
    "\n",
    "data_K562_filtered = data_K562[\n",
    "    ~data_K562.apply(lambda row: (row['sgRNA'], row['DNA']) in sgRNAs_val, axis=1)\n",
    "]\n",
    "\n",
    "data_II3_filtered = data_II3[\n",
    "    ~data_II3.apply(lambda row: (row['sgRNA'], row['DNA']) in sgRNAs_val, axis=1)\n",
    "]\n",
    "\n",
    "data_II4_filtered = data_II4[\n",
    "    ~data_II4.apply(lambda row: (row['sgRNA'], row['DNA']) in sgRNAs_val, axis=1)\n",
    "]\n",
    "\n",
    "data_II5_filtered = data_II5[\n",
    "    ~data_II5.apply(lambda row: (row['sgRNA'], row['DNA']) in sgRNAs_val, axis=1)\n",
    "]\n",
    "\n",
    "data_II6_filtered = data_II6[\n",
    "    ~data_II6.apply(lambda row: (row['sgRNA'], row['DNA']) in sgRNAs_val, axis=1)\n",
    "]\n",
    "\n",
    "print(len(data_HEK293T) - len(data_HEK293T_filtered))\n",
    "print(len(data_K562) - len(data_K562_filtered))\n",
    "print(len(data_II3) - len(data_II3_filtered))\n",
    "print(len(data_II4) - len(data_II4_filtered))\n",
    "print(len(data_II5) - len(data_II5_filtered))\n",
    "print(len(data_II6) - len(data_II6_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b03f454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132914\n",
      "132516\n",
      "20319\n",
      "20242\n",
      "217733\n",
      "217217\n",
      "294534\n",
      "294316\n",
      "95829\n",
      "95824\n",
      "383463\n",
      "383463\n"
     ]
    }
   ],
   "source": [
    "data_sets = [data_HEK293T, data_K562, data_II3, data_II4, data_II5, data_II6]\n",
    "data_sets_names = ['HEK293T','K562','II3','II4','II5','II6']\n",
    "i = 0\n",
    "\n",
    "def read_npz(file_path):\n",
    "    data  = np.load(file_path, allow_pickle=True)\n",
    "    ont   = data['ont']\n",
    "    offt  = data['offt']\n",
    "    label = data['label']\n",
    "    return ont, offt, label\n",
    "\n",
    "sgRNAs_val = []\n",
    "for index, row in validated_df_sgRNA_DNA.iterrows():\n",
    "    sgRNAs_val.append([row['Guide_sequence'], row['Target_sequence']])\n",
    "sgRNAs_val = set(zip(\n",
    "    validated_df_sgRNA_DNA['Guide_sequence'],\n",
    "    validated_df_sgRNA_DNA['Target_sequence']\n",
    "))\n",
    "\n",
    "for data_set in data_sets:\n",
    "    print(len(data_set))\n",
    "    \n",
    "    df_filtered = data_set[\n",
    "    ~data_set.apply(lambda row: (row['sgRNA'], row['DNA']) in sgRNAs_val, axis=1)\n",
    "    ]\n",
    "    print(len(df_filtered))\n",
    "\n",
    "    np.savez('./Datasets/training_sets_' + data_sets_names[i] + '_ori_filtered.npz', \n",
    "                 ont=df_filtered['sgRNA'].to_numpy(), \n",
    "                 offt=df_filtered['DNA'].to_numpy(),\n",
    "                label=df_filtered['label'].to_numpy())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d675423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21872\n",
      "filtered:236851\n",
      "2732\n",
      "filtered:39282\n",
      "4902\n",
      "filtered:399735\n",
      "21441\n",
      "filtered:529626\n",
      "5960\n",
      "filtered:187009\n",
      "18473\n",
      "filtered:750230\n"
     ]
    }
   ],
   "source": [
    "## BACKUP CODES\n",
    "## remove duplicates in public_datasets\n",
    "data_sets = ['HEK293T','K562','II3','II4','II5','II6']\n",
    "\n",
    "def read_npz(file_path):\n",
    "    data  = np.load(file_path, allow_pickle=True)\n",
    "    ont   = data['ont']\n",
    "    offt  = data['offt']\n",
    "    label = data['label']\n",
    "    return ont, offt, label\n",
    "\n",
    "sgRNAs_val = []\n",
    "for index, row in validated_df_sgRNA_DNA.iterrows():\n",
    "    sgRNAs_val.append([row['Guide_sequence'], row['Target_sequence']])\n",
    "sgRNAs_val = set(zip(\n",
    "    validated_df_sgRNA_DNA['Guide_sequence'],\n",
    "    validated_df_sgRNA_DNA['Target_sequence']\n",
    "))\n",
    "\n",
    "\n",
    "for data_set in data_sets:\n",
    "    filename = './Datasets/training_sets_' + data_set + '_1.npz'\n",
    "    ont, offt, label = read_npz(filename)\n",
    "    data = {\n",
    "        'ont': ont,\n",
    "        'offt': offt,\n",
    "        'label':label\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df_filtered = df[\n",
    "    ~df.apply(lambda row: (row['ont'], row['offt']) in sgRNAs_val, axis=1)\n",
    "    ]\n",
    "\n",
    "\n",
    "    np.savez('./Datasets/training_sets_' + data_set + '_filtered.npz', \n",
    "                 ont=df_filtered['ont'].to_numpy(), \n",
    "                 offt=df_filtered['offt'].to_numpy(),\n",
    "                label=df_filtered['label'].to_numpy())\n",
    "    #print(len(df))\n",
    "    print(len(df) - len(df_filtered))\n",
    "    print(\"filtered:{}\".format(len(df_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb7b08dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19908\n",
      "filtered:241930\n",
      "2615\n",
      "filtered:39122\n",
      "4592\n",
      "filtered:390306\n",
      "22829\n",
      "filtered:548364\n",
      "5928\n",
      "filtered:186636\n",
      "18352\n",
      "filtered:749966\n"
     ]
    }
   ],
   "source": [
    "## BACKUP CODES\n",
    "## remove duplicates in public_datasets\n",
    "data_sets = ['HEK293T','K562','II3','II4','II5','II6']\n",
    "\n",
    "def read_npz(file_path):\n",
    "    data  = np.load(file_path, allow_pickle=True)\n",
    "    ont   = data['ont']\n",
    "    offt  = data['offt']\n",
    "    label = data['label']\n",
    "    return ont, offt, label\n",
    "\n",
    "sgRNAs_val = []\n",
    "for index, row in validated_df_sgRNA_DNA.iterrows():\n",
    "    sgRNAs_val.append([row['Guide_sequence'], row['Target_sequence']])\n",
    "sgRNAs_val = set(zip(\n",
    "    validated_df_sgRNA_DNA['Guide_sequence'],\n",
    "    validated_df_sgRNA_DNA['Target_sequence']\n",
    "))\n",
    "\n",
    "\n",
    "for data_set in data_sets:\n",
    "    filename = './Datasets/training_sets_' + data_set + '_3.npz'\n",
    "    ont, offt, label = read_npz(filename)\n",
    "    data = {\n",
    "        'ont': ont,\n",
    "        'offt': offt,\n",
    "        'label':label\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df_filtered = df[\n",
    "    ~df.apply(lambda row: (row['ont'], row['offt']) in sgRNAs_val, axis=1)\n",
    "    ]\n",
    "\n",
    "\n",
    "    np.savez('./Datasets/training_sets_' + data_set + '_filtered2.npz', \n",
    "                 ont=df_filtered['ont'].to_numpy(), \n",
    "                 offt=df_filtered['offt'].to_numpy(),\n",
    "                label=df_filtered['label'].to_numpy())\n",
    "    #print(len(df))\n",
    "    print(len(df) - len(df_filtered))\n",
    "    print(\"filtered:{}\".format(len(df_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43859828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Integrate validation dataset\n",
    "\n",
    "##3.1 Exclude idential pairs in validated dataset\n",
    "sgRNAs_val = set(validated_onlyMis_df_sgRNA_DNA['Guide_sequence'])\n",
    "selected_sgRNAs_list = []\n",
    "for i in range(5):\n",
    "    random.seed(42+i)\n",
    "    selected_sgRNAs = random.sample(list(sgRNAs_val), 5)\n",
    "    selected_sgRNAs_list.append(selected_sgRNAs)\n",
    "    \n",
    "data_HEK293Ts = []\n",
    "data_K562s = []\n",
    "data_II3s = []\n",
    "data_II4s = []\n",
    "data_II5s = []\n",
    "data_II6s = []\n",
    "\n",
    "data_testing = []\n",
    "\n",
    "##3.2 Combine validation dataset with public datasets\n",
    "q = 0\n",
    "for sgRNAs_val in selected_sgRNAs_list:\n",
    "    \n",
    "    ## Validated_only dataset\n",
    "\n",
    "    \"\"\" Generate the validated_only datasets for training a\n",
    "    nd testing, the validated_only dataset contains same sgRNA as \n",
    "    public datasets\n",
    "    \"\"\"  \n",
    "\n",
    "    data_val = validated_onlyMis_df_sgRNA_DNA[~validated_onlyMis_df_sgRNA_DNA['Guide_sequence'].isin(sgRNAs_val)]\n",
    "    data_val.rename(columns={'Guide_sequence': 'sgRNA',\n",
    "                               'Target_sequence': 'DNA',\n",
    "                               'Validation': 'label'}, inplace=True)\n",
    "    \n",
    "    ## To save the validation datasets for training \n",
    "    data_val.to_csv('./Datasets/Val_only' + str(q) + '.csv', index = False) \n",
    "    \n",
    "    data_test = validated_onlyMis_df_sgRNA_DNA[validated_onlyMis_df_sgRNA_DNA['Guide_sequence'].isin(sgRNAs_val)]\n",
    "    data_test.rename(columns={'Guide_sequence': 'sgRNA',\n",
    "                               'Target_sequence': 'DNA',\n",
    "                               'Validation': 'label'}, inplace=True)\n",
    "    \n",
    "    ## To save the testing datasets\n",
    "    data_test.to_csv('./Datasets/Testing' + str(q) + '.csv', index = False)\n",
    "    q += 1\n",
    "    data_testing.append(data_test)\n",
    "    \n",
    "    print(len(data_val),len(data_test))\n",
    "    \n",
    "\n",
    "    ## filter sgRNAs from original dataset\n",
    "    ##? update: 2025-03-31 to remove all duplicates in validation pool?(all pairs)\n",
    "    \n",
    "    data_HEK293T_filtered = data_HEK293T[~data_HEK293T['sgRNA'].isin(sgRNAs_val)]\n",
    "    data_K562_filtered = data_K562[~data_K562['sgRNA'].isin(sgRNAs_val)]\n",
    "    data_II3_filtered = data_II3[~data_II3['sgRNA'].isin(sgRNAs_val)]\n",
    "    data_II4_filtered = data_II4[~data_II4['sgRNA'].isin(sgRNAs_val)]\n",
    "    data_II5_filtered = data_II5[~data_II5['sgRNA'].isin(sgRNAs_val)]\n",
    "    data_II6_filtered = data_II6[~data_II6['sgRNA'].isin(sgRNAs_val)]\n",
    "\n",
    "    \n",
    "    data_HEK293Ts.append(data_HEK293T_filtered)\n",
    "    data_K562s.append(data_K562_filtered)\n",
    "    data_II3s.append(data_II3_filtered)\n",
    "    data_II4s.append(data_II4_filtered)\n",
    "    data_II5s.append(data_II5_filtered)\n",
    "    data_II6s.append(data_II6_filtered)\n",
    "\n",
    "    \n",
    "    data_K562_combined = pd.concat([data_K562_filtered, data_val], ignore_index=True)\n",
    "    data_HEK293T_combined = pd.concat([data_HEK293T_filtered, data_val], ignore_index=True)\n",
    "    data_II3_combined = pd.concat([data_II3_filtered, data_val], ignore_index=True)\n",
    "    data_II4_combined = pd.concat([data_II4_filtered, data_val], ignore_index=True)\n",
    "    data_II5_combined = pd.concat([data_II5_filtered, data_val], ignore_index=True)\n",
    "    data_II6_combined = pd.concat([data_II6_filtered, data_val], ignore_index=True)\n",
    "\n",
    "    data_HEK293Ts.append(data_HEK293T_combined)\n",
    "    data_K562s.append(data_K562_combined)\n",
    "    data_II3s.append(data_II3_combined)\n",
    "    data_II4s.append(data_II4_combined)\n",
    "    data_II5s.append(data_II5_combined)\n",
    "    data_II6s.append(data_II6_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Resampling using SMOTEENN\n",
    "\n",
    "##4.1 Class and function for DNA sequence conversion \n",
    "class SeqTranslate:\n",
    "    def __init__(self):\n",
    "        # Define the mapping for encoding and decoding\n",
    "        self.nucleotide_to_number = {'A': 1, 'C': 2, 'G': 3, 'T': 4}\n",
    "        self.number_to_nucleotide = {v: k for k, v in self.nucleotide_to_number.items()}\n",
    "\n",
    "    def encode(self, sequence):\n",
    "        \"\"\"\n",
    "        Encode a nucleotide sequence into numeric representation.\n",
    "\n",
    "        Args:\n",
    "            sequence (str): The nucleotide sequence (e.g., \"ACGT\").\n",
    "\n",
    "        Returns:\n",
    "            list: A list of integers representing the sequence.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return [self.nucleotide_to_number[nuc] for nuc in sequence]\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Invalid nucleotide found in sequence. Allowed: A, C, G, T\")\n",
    "\n",
    "    def decode(self, numeric_sequence):\n",
    "        \"\"\"\n",
    "        Decode a numeric sequence back into nucleotide representation.\n",
    "\n",
    "        Args:\n",
    "            numeric_sequence (list): A list of integers (e.g., [1, 2, 3, 4]).\n",
    "\n",
    "        Returns:\n",
    "            str: The decoded nucleotide sequence.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return ''.join(self.number_to_nucleotide[num] for num in numeric_sequence)\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Invalid number found in sequence. Allowed: 1, 2, 3, 4\")\n",
    "\n",
    "# Example usage\n",
    "translator = SeqTranslate()\n",
    "\n",
    "# Encoding\n",
    "sequence = \"ACGTACG\"\n",
    "encoded = translator.encode(sequence)\n",
    "print(\"Encoded sequence:\", encoded)\n",
    "\n",
    "# Decoding\n",
    "decoded = translator.decode(encoded)\n",
    "print(\"Decoded sequence:\", decoded)\n",
    "\n",
    "\n",
    "def SMOTEENN_resampling(df, random_num):\n",
    "    \n",
    "    Encoded_seqs = []\n",
    "    Labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        on_target = row['sgRNA']\n",
    "        off_target = row['DNA']\n",
    "        label = row['label']\n",
    "\n",
    "        translator = SeqTranslate()\n",
    "        encoded_seq = translator.encode(on_target + off_target)\n",
    "\n",
    "        Encoded_seqs.append(encoded_seq)\n",
    "        Labels.append(int(label))\n",
    "\n",
    "    X = pd.DataFrame(Encoded_seqs)\n",
    "    y = pd.DataFrame(Labels)\n",
    "    \n",
    "    print(len(X),len(y))\n",
    "\n",
    "    ###1.5.2 resampling with SMOTEENN\n",
    "\n",
    "    smote_enn = SMOTEENN(random_state=random_num)\n",
    "\n",
    "    # Resample the data\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "    resampled_ont = []\n",
    "    resampled_offt = []\n",
    "    \n",
    "    print(len(X_resampled),len(y_resampled))\n",
    "\n",
    "    for index, row in X_resampled.iterrows():\n",
    "\n",
    "        translator = SeqTranslate()\n",
    "        decoded_seq = translator.decode(row)\n",
    "\n",
    "        on_target = decoded_seq[:23]\n",
    "        off_target = decoded_seq[23:]\n",
    "\n",
    "        resampled_ont.append(on_target)\n",
    "        resampled_offt.append(off_target)\n",
    "    \n",
    "    return resampled_ont,resampled_offt,y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259eac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##4.2 Dataset resampling using SMOTEENN\n",
    "\n",
    "\n",
    "training_sets_HEK293T = []\n",
    "training_sets_K562 = []\n",
    "training_sets_II3 = []\n",
    "training_sets_II4 = []\n",
    "training_sets_II5 = []\n",
    "training_sets_II6 = []\n",
    "label_sets_train_HEK293T = []\n",
    "label_sets_train_K562 = []\n",
    "label_sets_train_II3 = []\n",
    "label_sets_train_II4 = []\n",
    "label_sets_train_II5 = []\n",
    "label_sets_train_II6 = []\n",
    "\n",
    "# resampling and save the training datasets\n",
    "for i in range(10):\n",
    "    \n",
    "    data_HEK293T_filtered = data_HEK293Ts[i]\n",
    "    data_K562_filtered = data_K562s[i]\n",
    "    data_II3_filtered = data_II3s[i]\n",
    "    data_II4_filtered = data_II4s[i]\n",
    "    data_II5_filtered = data_II5s[i]\n",
    "    data_II6_filtered = data_II6s[i]\n",
    "\n",
    "    random_num = 42\n",
    "\n",
    "    resampled_ont_HEK293T, resampled_offt_HEK293T, y_resampled_HEK293T = SMOTEENN_resampling(data_HEK293T_filtered, random_num)\n",
    "    np.savez('training_sets_HEK293T_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_HEK293T)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_HEK293T)[0].to_numpy(),\n",
    "             label=y_resampled_HEK293T[0].to_numpy())\n",
    "    resampled_ont_K562, resampled_offt_K562, y_resampled_K562 = SMOTEENN_resampling(data_K562_filtered, random_num)\n",
    "    np.savez('training_sets_K562_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_K562)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_K562)[0].to_numpy(),\n",
    "            label=y_resampled_K562[0].to_numpy())\n",
    "    resampled_ont_II3, resampled_offt_II3, y_resampled_II3 = SMOTEENN_resampling(data_II3_filtered, random_num)\n",
    "    np.savez('training_sets_II3_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_II3)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_II3)[0].to_numpy(),\n",
    "            label=y_resampled_II3[0].to_numpy())\n",
    "    resampled_ont_II4, resampled_offt_II4, y_resampled_II4 = SMOTEENN_resampling(data_II4_filtered, random_num)\n",
    "    np.savez('training_sets_II4_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_II4)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_II4)[0].to_numpy(),\n",
    "            label=y_resampled_II4[0].to_numpy())\n",
    "    resampled_ont_II5, resampled_offt_II5, y_resampled_II5 = SMOTEENN_resampling(data_II5_filtered, random_num)\n",
    "    np.savez('training_sets_II5_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_II5)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_II5)[0].to_numpy(),\n",
    "            label=y_resampled_II5[0].to_numpy())\n",
    "    resampled_ont_II6, resampled_offt_II6, y_resampled_II6 = SMOTEENN_resampling(data_II6_filtered, random_num)\n",
    "    np.savez('training_sets_II6_' + str(i) + '.npz', \n",
    "             ont=pd.DataFrame(resampled_ont_II6)[0].to_numpy(), \n",
    "             offt=pd.DataFrame(resampled_offt_II6)[0].to_numpy(),\n",
    "            label=y_resampled_II6[0].to_numpy())\n",
    "\n",
    "    training_sets_HEK293T.append([pd.DataFrame(resampled_ont_HEK293T)[0].to_numpy(),pd.DataFrame(resampled_offt_HEK293T)[0].to_numpy()])\n",
    "    training_sets_K562.append([pd.DataFrame(resampled_ont_K562)[0].to_numpy(),pd.DataFrame(resampled_offt_K562)[0].to_numpy()])\n",
    "    training_sets_II3.append([pd.DataFrame(resampled_ont_II3)[0].to_numpy(),pd.DataFrame(resampled_offt_II3)[0].to_numpy()])\n",
    "    training_sets_II4.append([pd.DataFrame(resampled_ont_II4)[0].to_numpy(),pd.DataFrame(resampled_offt_II4)[0].to_numpy()])\n",
    "    training_sets_II5.append([pd.DataFrame(resampled_ont_II5)[0].to_numpy(),pd.DataFrame(resampled_offt_II5)[0].to_numpy()])\n",
    "    training_sets_II6.append([pd.DataFrame(resampled_ont_II6)[0].to_numpy(),pd.DataFrame(resampled_offt_II6)[0].to_numpy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c438f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##5 Val only dataset w/real testing \n",
    "\n",
    "val_only_ori = pd.read_csv('./Datasets/val_only/validated_onlyMis_df_sgRNA_DNA.csv', sep = ',')\n",
    "\n",
    "\n",
    "testing_files = ['./Datasets/real_testing/Testing0.csv',\n",
    "                 './Datasets/real_testing//Testing1.csv',\n",
    "                 './Datasets/real_testing//Testing2.csv',\n",
    "                 './Datasets/real_testing//Testing3.csv',\n",
    "                 './Datasets/real_testing//Testing4.csv'\n",
    "]\n",
    "\n",
    "\n",
    "i = 0\n",
    "for filename in testing_files:\n",
    "    df = pd.read_csv(filename, sep=',')\n",
    "    ont = df['sgRNA'].to_numpy()\n",
    "    offt = df['DNA'].to_numpy()\n",
    "    label = df['label'].to_numpy()\n",
    "    testing_set = set(ont)\n",
    "    training_set = val_only_ori[~val_only_ori['Guide_sequence'].isin(testing_set)]\n",
    "    \n",
    "    filename = './Datasets/val_only/val_only_training_' + str(i) + '.csv'\n",
    "    \n",
    "    training_set.to_csv(filename, index = False)\n",
    "    \n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578409d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BACKUP CODES\n",
    "## remove duplicates in public_datasets\n",
    "\n",
    "def read_npz(file_path):\n",
    "    data  = np.load(file_path, allow_pickle=True)\n",
    "    ont   = data['ont']\n",
    "    offt  = data['offt']\n",
    "    label = data['label']\n",
    "    return ont, offt, label\n",
    "filename = './Datasets/training_sets_HEK293T_3.npz'\n",
    "ont, offt, label = read_npz(filename)\n",
    "data = {\n",
    "    'ont': ont,\n",
    "    'offt': offt,\n",
    "    'label':label\n",
    "}\n",
    "\n",
    "data_HEK293T = pd.DataFrame(data)\n",
    "\n",
    "len(data_HEK293T)\n",
    "\n",
    "sgRNAs_val = []\n",
    "for index, row in validated_df_sgRNA_DNA.iterrows():\n",
    "    sgRNAs_val.append([row['Guide_sequence'], row['Target_sequence']])\n",
    "sgRNAs_val = set(zip(\n",
    "    validated_df_sgRNA_DNA['Guide_sequence'],\n",
    "    validated_df_sgRNA_DNA['Target_sequence']\n",
    "))\n",
    "\n",
    "data_HEK293T_filtered = data_HEK293T[\n",
    "    ~data_HEK293T.apply(lambda row: (row['ont'], row['offt']) in sgRNAs_val, axis=1)\n",
    "]\n",
    "\n",
    "np.savez('./Datasets/training_sets_HEK293T_2.npz', \n",
    "             ont=data_HEK293T_filtered['ont'].to_numpy(), \n",
    "             offt=data_HEK293T_filtered['offt'].to_numpy(),\n",
    "            label=data_HEK293T_filtered['label'].to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (OT_review)",
   "language": "python",
   "name": "ot_review"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
